{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From raw image to Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN\n",
    "\n",
    "# mtcnn = MTCNN(post_process=False, device=\"cuda:0\")\n",
    "mtcnn = MTCNN(post_process=False, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size = (128, 128)\n",
    "\n",
    "\n",
    "def mtcnn_landmark(img, boxes, points):\n",
    "    # order sort\n",
    "    boxes_resz = boxes[0].astype(int)\n",
    "    boxes_resz[:, 2] = boxes_resz[:, 2] - boxes_resz[:, 0]\n",
    "    boxes_resz[:, 3] = boxes_resz[:, 3] - boxes_resz[:, 1]\n",
    "    width, height = np.mean(boxes_resz[:, 2]), np.mean(boxes_resz[:, 3])\n",
    "\n",
    "    points_resz = points[0].astype(np.float32)\n",
    "    points_resz = sorted(points_resz, key=lambda pts: pts[0][1])\n",
    "    points_resz[0:6] = sorted(points_resz[0:6], key=lambda pts: pts[0][0])\n",
    "    points_resz[6:12] = sorted(points_resz[6:12], key=lambda pts: pts[0][0])\n",
    "    points_resz[12:18] = sorted(points_resz[12:18], key=lambda pts: pts[0][0])\n",
    "    points_resz[18:24] = sorted(points_resz[18:24], key=lambda pts: pts[0][0])\n",
    "    points_resz[24:30] = sorted(points_resz[24:30], key=lambda pts: pts[0][0])\n",
    "    points_resz[30:36] = sorted(points_resz[30:36], key=lambda pts: pts[0][0])\n",
    "    points_resz.reverse()\n",
    "\n",
    "    pts_zero = points_resz[0]\n",
    "    pts_zero_c = np.mean(pts_zero, axis=0)\n",
    "    left_top = np.array([pts_zero_c[0] - width / 2, pts_zero_c[1] - height / 2])\n",
    "\n",
    "    # crop and save\n",
    "    img_gray = cv2.cvtColor(img[0], cv2.COLOR_BGR2GRAY)\n",
    "    st = []\n",
    "    for i in range(len(points_resz)):\n",
    "\n",
    "        pts = points_resz[i]\n",
    "        pts_c = np.mean(pts, axis=0)\n",
    "        left_top_new = left_top + (pts_c - pts_zero_c)\n",
    "\n",
    "        box = np.array([*left_top_new, left_top_new[0] + width, left_top_new[1] + height], dtype=int)\n",
    "\n",
    "        img_gray_cropped = img_gray[max(0, box[1]) : max(0, box[3]), max(0, box[0]) : max(0, box[2])]\n",
    "        st.append(cv2.resize(img_gray_cropped, new_size))\n",
    "\n",
    "    return np.stack(st).transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01-live\\01-live.bmp (128, 128, 36)\n",
      "02-paper\\02-print.bmp (128, 128, 36)\n",
      "03-iphone\\03-iphone.bmp (128, 128, 36)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as io\n",
    "\n",
    "# path_base = \"F:/gist-grad/research/projects/hsi-face-recog/20240724-demo/\"\n",
    "path_base = \"C:/Users/youngin/Desktop/2025_project/python/dataset/01-yi_choi\"\n",
    "\n",
    "for file in glob.glob(\"**/*.bmp\", root_dir=path_base):\n",
    "\n",
    "    img = cv2.imread(os.path.join(path_base, file))\n",
    "    H, W, C = img.shape\n",
    "    img = img.reshape(1, H, W, C)\n",
    "    boxes, probs, points = mtcnn.detect(img, landmarks=True)\n",
    "    cube = mtcnn_landmark(img, boxes, points)\n",
    "    print(file, cube.shape)\n",
    "\n",
    "    io.savemat(os.path.join(path_base, \".\".join([*file.split(\".\")[:-1], \"mat\"])), {\"cube_meas\": cube})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jioh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
